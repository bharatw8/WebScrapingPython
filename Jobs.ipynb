{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import urllib3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_title_from_result(soup): \n",
    "    jobs = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "            jobs.append(a[\"title\"])\n",
    "    return(jobs)\n",
    "\n",
    "def extract_company_from_result(soup): \n",
    "    companies = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                companies.append(b.text.strip())\n",
    "            else:\n",
    "                sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-link-source\"})\n",
    "            for span in sec_try:\n",
    "                companies.append(span.text.strip())\n",
    "    return(companies)\n",
    "\n",
    "def extract_location_from_result(soup): \n",
    "    locations = []\n",
    "    spans = soup.findAll(\"span\", attrs={\"class\": \"location\"})\n",
    "    for span in spans:\n",
    "        locations.append(span.text)\n",
    "    return(locations)\n",
    "\n",
    "def extract_salary_from_result(soup): \n",
    "    salaries = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        try:\n",
    "            salaries.append(div.find(\"nobr\").text)\n",
    "        except:\n",
    "            try:\n",
    "                div_two = div.find(name=\"div\", attrs={\"class\":\"salarySnippet salarySnippetDemphasize\"})\n",
    "                div_three = div_two.find(name=\"span\", attrs={\"class\":\"salary no-wrap\"})\n",
    "                salaries.append(div_three.text.strip())\n",
    "            except:\n",
    "                salaries.append(\"Nothing_found\")\n",
    "    return(salaries)\n",
    "\n",
    "def extract_links_from_result(soup): \n",
    "    links = []\n",
    "    lnk_final = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        for a in div.find_all(name=\"div\", attrs={\"class\":\"title\"}):\n",
    "            for b in a.find_all(name=\"a\", attrs={\"class\":\"jobtitle turnstileLink\", \"data-tn-element\":\"jobTitle\"}):\n",
    "                links.append(b[\"href\"])    \n",
    "    return(links)\n",
    "\n",
    "def extract_skills_from_result(link):\n",
    "    try:\n",
    "        page = requests.get(link,timeout=1)\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "        result = soup.find(\"div\", {\"id\":\"jobDescriptionText\", \"class\":\"jobsearch-jobDescriptionText\"})\n",
    "        return result.text\n",
    "    except:\n",
    "        return(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Job Position and scrape related data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc=[]\n",
    "sal=[]\n",
    "ttl=[]\n",
    "cmp=[]\n",
    "lnk=[]\n",
    "job_desc=[]\n",
    "job_role=\"Statistical Data Analyst\"\n",
    "location=\"Ontario\"\n",
    "\n",
    "for i in range(0,500,10):\n",
    "    URL = (\"https://www.indeed.ca/jobs?q=\"+urllib.parse.quote_plus(job_role)+\"&l=\"+urllib.parse.quote_plus(location)+\"&fromage=15&start=\"+str(i))\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "#     print(soup.prettify())\n",
    "    for x in extract_job_title_from_result(soup):\n",
    "        ttl.append(x)\n",
    "    for x in extract_salary_from_result(soup):\n",
    "        sal.append(x)\n",
    "    for x in extract_company_from_result(soup):\n",
    "        cmp.append(x)\n",
    "    for x in extract_location_from_result(soup):\n",
    "        loc.append(x)\n",
    "    for x in extract_links_from_result(soup):\n",
    "        lnk.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1285\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "print(len(lnk))\n",
    "for x in range(0,len(lnk)):\n",
    "    job_desc.append(extract_skills_from_result(\"https://ca.indeed.com\"+lnk[x]))\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Skills from Job Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills=[\"Python\",\"R\",\"Tableau\",\"AWS\",\"Azure\",\"C#\",\"Java\",\"PowerBI\",\"Microsoft\", \"SQL\",\"MySQL\",\"PostgreSQL\",\"SSRS\",\"SSIS\",\"Office\", \"Powerpoint\",\"Excel\",\"Word\",\"Hadoop\",\"Hive\",\"Splunk\",\"Pig\",\"Spark\",\"Scala\",\"Cloudera\",\"C++\",\"Linux\", \"SAS\",\"Access\",\"NoSQL\", \"JavaScript\", \"MongoDB\", \"Matlab\"]\n",
    "seperator = ', '\n",
    "final_skills=[]\n",
    "final_tab=[]\n",
    "for j in job_desc:\n",
    "    for i in skills:\n",
    "        if i.lower() in j.lower():\n",
    "            final_skills.append(i)\n",
    "    final_tab.append(seperator.join(final_skills))\n",
    "    final_skills.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1285"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Excel File from the scraped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {}\n",
    "\n",
    "columns[\"JobTitle\"] = ttl \n",
    "columns[\"Salary\"] = sal\n",
    "columns[\"CompanyName\"] = cmp\n",
    "columns[\"Location\"] = loc\n",
    "columns[\"Skills\"] = final_tab\n",
    "\n",
    "data = list(zip(columns[\"JobTitle\"],columns[\"Salary\"],columns[\"CompanyName\"],columns[\"Location\"],columns[\"Skills\"]))\n",
    "\n",
    "df = pd.DataFrame(data = data)\n",
    "\n",
    "df.to_csv(\"D://jobs_\"+job_role+\".csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1285\n",
      "1285\n",
      "1428\n",
      "988\n",
      "1285\n"
     ]
    }
   ],
   "source": [
    "print(len(ttl))\n",
    "print(len(sal))\n",
    "print(len(cmp))\n",
    "print(len(loc))\n",
    "print(len(final_tab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
